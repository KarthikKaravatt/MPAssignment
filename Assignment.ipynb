{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1 #\n",
    "Karthik Karavatt\n",
    "2061996\n",
    "5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "227072906891b550"
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# Read the image\n",
    "img = cv.imread(\"digits.png\")\n",
    "# Convert the image to grayscale\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:32.827989795Z",
     "start_time": "2023-10-07T19:07:32.779945962Z"
    }
   },
   "id": "19764a5e11cfb1b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2.1 Data Preparation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6938d6978795077"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1\n",
    "Split the image into 5000 images of size 20x20 pixels each. Each image contains a digit.\n",
    "Store this data in a numpy array\n",
    "\n",
    "We know the digit is 20x20 pixels. So we can split the image into 5000 images of size 20x20 pixels each.\n",
    "As the image is 1000x500 pixels, we can split the image into 50 rows and 100 columns."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d0c4a9efd1788a6"
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Split the image into 5000 cells of size 20x20 pixels each\n",
    "data_cells = np.array([np.hsplit(row, 100) for row in np.vsplit(img, 50)])\n",
    "\n",
    "data = np.array(data_cells)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:32.860163644Z",
     "start_time": "2023-10-07T19:07:32.803911179Z"
    }
   },
   "id": "43df7029e5a18bef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2\n",
    "Split the data into training and test sets. Use the first 1000 images for training and the rest for testing.\n",
    "Every 5th row is a different digit, there are 5 rows of each digit and the digits go up to 9, we can use one row of each digit for training and the rest for testing. So we take one row from every 5 rows for training and the rest for testing\n",
    "."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e32665efa115fd3d"
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "# Select every 5th row for testing\n",
    "test_data = data[::5]\n",
    "\n",
    "# Select all but every 5th row for training\n",
    "train_data = np.delete(data, np.arange(0, data.shape[0], 5), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:32.884071023Z",
     "start_time": "2023-10-07T19:07:32.813244633Z"
    }
   },
   "id": "8dc09667414a028"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.3\n",
    "Write the images to a folders. The images should be written to the train and test directories."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bee6d63f726fa13"
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2 as cv\n",
    "\n",
    "# Define your directory paths\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "# If the directories already exist, remove them and their contents\n",
    "for dir_path in [train_dir, test_dir]:\n",
    "    if os.path.exists(dir_path) and os.path.isdir(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "\n",
    "    # Create the directories\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Save your train and test data to the respective directories as JPEGs\n",
    "\n",
    "for i in range(train_data.shape[0]):\n",
    "    for j in range(train_data.shape[1]):\n",
    "        digit = i // 4  # The digit is determined by integer division of the row index by 4\n",
    "        row = i % 4  # The row is determined by the remainder of the row index divided by 4\n",
    "        cv.imwrite(os.path.join(train_dir, f'train_{digit}_{row}_{j}.jpg'), train_data[i, j])\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    for j in range(test_data.shape[1]):\n",
    "        cv.imwrite(os.path.join(test_dir, f'test_{i}_{j}.jpg'), test_data[i, j])\n",
    "\n",
    "\n",
    "def load_images_to_array(path):\n",
    "    # Get the list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Sort the files\n",
    "    files.sort()\n",
    "    # Load the images into a numpy array\n",
    "    images = np.array([cv.imread(os.path.join(path, file), cv.IMREAD_GRAYSCALE) for file in files])\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:33.122884014Z",
     "start_time": "2023-10-07T19:07:32.868478653Z"
    }
   },
   "id": "67d1edd4bb860809"
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:33.123184409Z",
     "start_time": "2023-10-07T19:07:33.099602807Z"
    }
   },
   "id": "b279fb43533aa636"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2.2: Nearest Neighbor method for image classification "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36c14c7f08734d81"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this task we will use the k - nearest neighbor method to classify the images in the test set.\n",
    "### 2.2\n",
    "label the images in the training set. The labels should be the digit in the image."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dd1d554d6a2e614"
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [],
   "source": [
    "# Load the images from the train and test directories into numpy arrays\n",
    "train_data = load_images_to_array(train_dir)\n",
    "test_data = load_images_to_array(test_dir)\n",
    "\n",
    "# Reshape the training data to be 2D and convert to float32\n",
    "train_data = train_data.reshape(-1, 400)\n",
    "train_data = np.float32(train_data)\n",
    "\n",
    "# Reshape the test data to be 2D and convert to float32\n",
    "test_data = test_data.reshape(-1, 400)\n",
    "test_data = np.float32(test_data)\n",
    "\n",
    "# Create the labels for the training data\n",
    "train_labels = np.repeat(np.arange(10), 400).reshape(-1, 1)\n",
    "# Create the labels for the test data\n",
    "test_labels = np.repeat(np.arange(10), 100).reshape(-1, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:33.275836914Z",
     "start_time": "2023-10-07T19:07:33.105058774Z"
    }
   },
   "id": "cbb63a57109d24d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Implement the k - nearest neighbor method to classify the images in the test set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49e98596259c3ef1"
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 93.10000000000001%\n",
      "k = 3\n",
      "$\\begin{bmatrix}\n",
      "100&0&0&0&0&0&0&0&0&0\\\\\n",
      "0&98&1&1&0&0&0&0&0&0\\\\\n",
      "2&5&88&0&0&1&0&4&0&0\\\\\n",
      "1&0&2&91&0&3&1&2&0&0\\\\\n",
      "0&1&0&0&90&1&1&0&0&7\\\\\n",
      "0&2&1&6&0&88&1&0&0&2\\\\\n",
      "1&0&0&0&0&0&99&0&0&0\\\\\n",
      "0&3&0&0&1&0&0&92&0&4\\\\\n",
      "0&4&1&1&0&0&0&0&93&1\\\\\n",
      "4&0&0&1&2&0&0&1&0&92\\\\\n",
      "\\end{bmatrix}$\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy_and_confusion_matrix(k):\n",
    "    # Create the kNN model\n",
    "    knn = cv.ml.KNearest_create()\n",
    "    knn.train(train_data, cv.ml.ROW_SAMPLE, train_labels)\n",
    "    ret, result, neighbours, dist = knn.findNearest(test_data, k=k)\n",
    "    # Calculate the accuracy of classification\n",
    "    matches = np.equal(result, test_labels)\n",
    "    correct = np.count_nonzero(matches)\n",
    "    accuracy = correct * (100.0 / result.size)\n",
    "    print(f'Accuracy is {accuracy}%')\n",
    "\n",
    "    # Convert the test labels and the predicted results to integer type\n",
    "    test_labels_int = test_labels.astype(int)\n",
    "    result_int = result.astype(int)\n",
    "\n",
    "    # Get the number of classes\n",
    "    num_classes = len(np.unique(test_labels_int))\n",
    "\n",
    "    # Initialize the confusion matrix\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n",
    "\n",
    "    # Populate the confusion matrix\n",
    "    for j in range(len(test_labels_int)):\n",
    "        confusion_matrix[test_labels_int[j][0]][result_int[j][0]] += 1\n",
    "\n",
    "    # Print the confusion matrix in latex format for markdown\n",
    "    print(f'k = {k}')\n",
    "    print(r'$\\begin{bmatrix}')\n",
    "    for row in confusion_matrix:\n",
    "        for i, col in enumerate(row):\n",
    "            if i == len(row) - 1:\n",
    "                print(f'{col}\\\\\\\\')\n",
    "            else:\n",
    "                print(f'{col}&', end='')\n",
    "    print(r'\\end{bmatrix}$')\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "get_accuracy_and_confusion_matrix(3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:33.319858463Z",
     "start_time": "2023-10-07T19:07:33.218092745Z"
    }
   },
   "id": "a5c66d5a1b1fc814"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| k  | Accuracy           |\n",
    "|----|--------------------|\n",
    "| 1  | 92.60000000000001% |\n",
    "| 2  | 92.2%              |\n",
    "| 3  | 93.10000000000001% |\n",
    "| 4  | 92.7%              |\n",
    "| 5  | 92.10000000000001% |\n",
    "| 6  | 92.0%              |\n",
    "| 7  | 92.0%              |\n",
    "| 8  | 91.9%              |\n",
    "| 9  | 91.80000000000001% |\n",
    "| 10 | 92.0%              |\n",
    "| 11 | 90.9%              |\n",
    "| 12 | 90.9%              |\n",
    "| 13 | 90.80000000000001% |\n",
    "| 14 | 90.80000000000001% |\n",
    "| 15 | 90.60000000000001% |\n",
    "| 16 | 90.10000000000001% |\n",
    "| 17 | 90.2%              |\n",
    "| 18 | 90.30000000000001% |\n",
    "| 19 | 90.10000000000001% |\n",
    "| 20 | 89.9%              |\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "534bbd61aa26b640"
  },
  {
   "cell_type": "markdown",
   "source": [
    "k = 1\n",
    "$\\begin{bmatrix}\n",
    "98&0&2&0&0&0&0&0&0&0\\\\\n",
    "0&97&2&1&0&0&0&0&0&0\\\\\n",
    "1&3&86&3&1&1&0&4&0&1\\\\\n",
    "0&0&0&93&0&2&1&2&2&0\\\\\n",
    "0&0&0&0&90&1&0&1&0&8\\\\\n",
    "0&1&1&4&0&89&1&0&0&4\\\\\n",
    "1&0&0&0&1&1&97&0&0&0\\\\\n",
    "0&3&0&0&1&0&0&91&0&5\\\\\n",
    "0&2&0&2&0&1&0&0&95&0\\\\\n",
    "3&0&0&0&2&0&1&4&0&90\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 2\n",
    "$\\begin{bmatrix}\n",
    "100&0&0&0&0&0&0&0&0&0\\\\\n",
    "0&98&2&0&0&0&0&0&0&0\\\\\n",
    "3&5&87&0&0&1&0&4&0&0\\\\\n",
    "1&0&3&91&0&1&1&2&1&0\\\\\n",
    "0&1&0&0&95&0&0&2&0&2\\\\\n",
    "0&1&1&9&2&86&0&0&0&1\\\\\n",
    "1&1&0&0&1&2&95&0&0&0\\\\\n",
    "0&4&0&0&2&0&0&93&0&1\\\\\n",
    "0&5&1&1&0&3&0&0&90&0\\\\\n",
    "4&0&0&1&4&0&0&4&0&87\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 3\n",
    "$\\begin{bmatrix}\n",
    "100&0&0&0&0&0&0&0&0&0\\\\\n",
    "0&98&1&1&0&0&0&0&0&0\\\\\n",
    "2&5&88&0&0&1&0&4&0&0\\\\\n",
    "1&0&2&91&0&3&1&2&0&0\\\\\n",
    "0&1&0&0&90&1&1&0&0&7\\\\\n",
    "0&2&1&6&0&88&1&0&0&2\\\\\n",
    "1&0&0&0&0&0&99&0&0&0\\\\\n",
    "0&3&0&0&1&0&0&92&0&4\\\\\n",
    "0&4&1&1&0&0&0&0&93&1\\\\\n",
    "4&0&0&1&2&0&0&1&0&92\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 4\n",
    "$\\begin{bmatrix}\n",
    "100&0&0&0&0&0&0&0&0&0\\\\\n",
    "0&97&1&1&1&0&0&0&0&0\\\\\n",
    "2&7&86&0&0&1&0&4&0&0\\\\\n",
    "1&0&2&92&0&1&1&2&1&0\\\\\n",
    "0&1&0&0&93&0&1&0&0&5\\\\\n",
    "0&2&1&4&0&90&1&0&0&2\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&5&0&0&1&0&0&91&0&3\\\\\n",
    "0&3&0&2&0&0&0&0&94&1\\\\\n",
    "1&0&1&2&5&0&2&3&0&86\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 5\n",
    "$\\begin{bmatrix}\n",
    "99&0&0&0&0&0&1&0&0&0\\\\\n",
    "0&98&0&1&0&1&0&0&0&0\\\\\n",
    "2&6&86&0&0&1&0&5&0&0\\\\\n",
    "1&0&2&91&0&2&1&2&1&0\\\\\n",
    "0&2&0&0&90&1&2&0&0&5\\\\\n",
    "0&1&1&5&0&88&2&0&0&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&4&0&0&1&0&0&92&0&3\\\\\n",
    "0&3&1&3&0&1&1&0&90&1\\\\\n",
    "1&0&1&1&2&0&2&4&0&89\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 6\n",
    "$\\begin{bmatrix}\n",
    "99&0&0&0&0&0&1&0&0&0\\\\\n",
    "0&98&0&1&0&1&0&0&0&0\\\\\n",
    "3&7&86&0&0&0&0&4&0&0\\\\\n",
    "0&0&2&92&0&1&1&2&1&1\\\\\n",
    "0&2&0&0&92&0&2&0&0&4\\\\\n",
    "0&1&1&6&1&88&1&0&0&2\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&5&0&0&1&0&0&90&0&4\\\\\n",
    "0&4&1&2&0&2&1&0&89&1\\\\\n",
    "3&0&0&2&2&1&0&4&0&88\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 7\n",
    "$\\begin{bmatrix}\n",
    "98&0&0&0&0&2&0&0&0&0\\\\\n",
    "0&98&1&1&0&0&0&0&0&0\\\\\n",
    "2&7&84&0&0&1&0&6&0&0\\\\\n",
    "0&0&2&92&0&1&1&2&1&1\\\\\n",
    "0&2&0&0&92&0&2&0&0&4\\\\\n",
    "0&1&1&5&0&88&2&0&0&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&5&0&0&0&0&0&92&0&3\\\\\n",
    "0&4&0&4&0&1&1&0&89&1\\\\\n",
    "2&0&0&1&2&1&0&5&0&89\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 8\n",
    "$\\begin{bmatrix}\n",
    "99&0&0&0&0&0&1&0&0&0\\\\\n",
    "0&97&2&0&1&0&0&0&0&0\\\\\n",
    "2&8&85&0&0&1&0&4&0&0\\\\\n",
    "0&0&2&92&0&1&1&2&1&1\\\\\n",
    "0&3&0&0&90&0&2&0&0&5\\\\\n",
    "0&1&1&7&0&87&1&0&0&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&5&0&0&0&0&0&92&0&3\\\\\n",
    "0&4&0&2&0&1&1&0&91&1\\\\\n",
    "3&0&0&1&2&0&1&5&0&88\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 9\n",
    "$\\begin{bmatrix}\n",
    "97&0&0&0&0&2&1&0&0&0\\\\\n",
    "0&98&0&1&0&1&0&0&0&0\\\\\n",
    "2&9&84&0&0&1&0&4&0&0\\\\\n",
    "0&0&2&91&0&2&1&2&1&1\\\\\n",
    "0&3&0&0&90&0&2&0&0&5\\\\\n",
    "0&1&1&6&0&88&1&0&0&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&5&0&0&0&0&0&92&0&3\\\\\n",
    "0&4&0&2&0&2&1&0&90&1\\\\\n",
    "2&0&0&1&1&1&0&5&0&90\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 10\n",
    "$\\begin{bmatrix}\n",
    "98&0&0&0&0&1&1&0&0&0\\\\\n",
    "0&98&0&1&0&1&0&0&0&0\\\\\n",
    "2&9&84&0&0&1&0&4&0&0\\\\\n",
    "1&0&2&92&0&1&1&2&0&1\\\\\n",
    "0&3&0&0&90&0&2&0&0&5\\\\\n",
    "0&1&1&7&1&87&1&0&0&2\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&5&0&0&0&0&0&92&0&3\\\\\n",
    "0&4&0&2&0&2&1&0&90&1\\\\\n",
    "2&0&0&1&1&1&0&4&0&91\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 11\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&98&0&0&0&1&0&0&0&1\\\\\n",
    "3&9&82&0&0&1&0&5&0&0\\\\\n",
    "1&1&1&90&0&2&1&2&0&2\\\\\n",
    "0&3&0&0&90&0&2&0&0&5\\\\\n",
    "0&1&1&7&0&86&1&0&1&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&6&0&0&1&0&0&90&0&3\\\\\n",
    "0&4&0&2&0&2&1&0&90&1\\\\\n",
    "2&0&0&1&2&1&0&5&0&89\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 12\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&3&1&0&0&0\\\\\n",
    "0&97&0&0&1&1&0&0&0&1\\\\\n",
    "3&8&82&0&0&1&0&6&0&0\\\\\n",
    "1&1&2&90&0&2&1&2&0&1\\\\\n",
    "0&4&0&0&88&1&2&0&0&5\\\\\n",
    "0&1&1&5&0&89&1&0&0&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&6&0&0&1&0&0&90&0&3\\\\\n",
    "0&4&0&2&0&2&1&0&90&1\\\\\n",
    "2&0&0&1&3&0&1&4&0&89\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 13\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&98&0&0&0&1&0&0&0&1\\\\\n",
    "3&9&80&0&0&1&0&7&0&0\\\\\n",
    "1&1&1&91&0&1&1&3&0&1\\\\\n",
    "0&4&0&0&90&0&2&0&0&4\\\\\n",
    "0&1&1&5&1&88&1&0&0&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&6&0&0&0&0&0&91&0&3\\\\\n",
    "0&3&0&4&0&3&1&0&88&1\\\\\n",
    "2&0&1&1&2&0&1&5&0&88\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 14\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&98&0&0&0&1&0&1&0&0\\\\\n",
    "2&9&81&0&0&1&0&6&1&0\\\\\n",
    "1&1&1&91&0&1&1&3&0&1\\\\\n",
    "0&4&0&0&87&1&2&0&0&6\\\\\n",
    "0&1&1&5&1&88&1&0&0&3\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&6&0&0&0&0&0&91&0&3\\\\\n",
    "0&3&0&3&0&3&1&0&89&1\\\\\n",
    "2&0&0&1&3&0&1&4&0&89\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 15\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&97&0&0&1&1&0&0&0&1\\\\\n",
    "2&9&81&0&0&1&0&6&0&1\\\\\n",
    "1&1&1&91&0&1&1&3&0&1\\\\\n",
    "0&4&0&0&90&0&2&0&0&4\\\\\n",
    "0&1&1&6&0&86&2&0&0&4\\\\\n",
    "1&1&0&0&0&0&98&0&0&0\\\\\n",
    "0&7&0&0&1&0&0&88&0&4\\\\\n",
    "0&3&0&3&0&3&1&0&89&1\\\\\n",
    "2&0&0&1&1&0&1&5&0&90\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 16\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&97&0&0&1&1&0&0&0&1\\\\\n",
    "2&9&80&0&0&1&0&6&1&1\\\\\n",
    "1&1&1&89&0&2&1&3&0&2\\\\\n",
    "0&4&0&0&88&0&2&0&0&6\\\\\n",
    "0&1&1&5&0&88&1&0&0&4\\\\\n",
    "1&1&0&0&0&1&97&0&0&0\\\\\n",
    "0&7&0&0&1&0&0&88&0&4\\\\\n",
    "0&5&0&4&0&2&1&0&87&1\\\\\n",
    "2&0&0&1&1&0&1&4&0&91\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 17\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&97&0&0&1&1&0&1&0&0\\\\\n",
    "3&9&79&0&0&1&0&6&1&1\\\\\n",
    "1&1&2&87&0&2&1&3&0&3\\\\\n",
    "0&4&0&0&90&0&2&0&0&4\\\\\n",
    "0&1&1&6&1&86&2&0&0&3\\\\\n",
    "1&1&0&0&0&1&97&0&0&0\\\\\n",
    "0&6&0&0&1&0&0&90&0&3\\\\\n",
    "0&3&0&3&0&3&1&0&89&1\\\\\n",
    "2&0&0&1&1&0&1&4&0&91\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 18\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&97&0&0&1&1&0&1&0&0\\\\\n",
    "2&9&81&0&0&1&0&5&1&1\\\\\n",
    "1&1&2&85&0&3&1&3&0&4\\\\\n",
    "0&4&0&0&90&0&2&0&0&4\\\\\n",
    "0&1&1&6&1&87&1&0&0&3\\\\\n",
    "1&1&0&0&0&1&97&0&0&0\\\\\n",
    "0&6&0&0&1&0&0&90&0&3\\\\\n",
    "0&3&0&3&0&3&1&0&89&1\\\\\n",
    "2&1&0&1&1&0&1&3&0&91\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 19\n",
    "$\\begin{bmatrix}\n",
    "96&0&0&0&0&2&2&0&0&0\\\\\n",
    "0&97&0&0&1&1&0&1&0&0\\\\\n",
    "2&9&81&0&0&1&0&5&1&1\\\\\n",
    "1&1&2&85&0&3&1&3&0&4\\\\\n",
    "0&4&0&0&91&0&2&0&0&3\\\\\n",
    "0&1&1&6&1&86&2&0&0&3\\\\\n",
    "1&1&0&0&0&1&97&0&0&0\\\\\n",
    "0&7&0&0&1&0&0&89&0&3\\\\\n",
    "0&3&0&3&0&3&1&0&89&1\\\\\n",
    "2&1&0&1&1&0&1&4&0&90\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "k = 20\n",
    "$\\begin{bmatrix}\n",
    "96&0&1&0&0&2&1&0&0&0\\\\\n",
    "0&97&0&0&1&1&0&0&0&1\\\\\n",
    "2&9&81&0&0&1&0&5&1&1\\\\\n",
    "1&1&2&85&0&3&1&3&0&4\\\\\n",
    "0&4&0&0&90&0&2&0&0&4\\\\\n",
    "0&1&1&6&1&87&1&0&0&3\\\\\n",
    "1&1&0&0&0&1&97&0&0&0\\\\\n",
    "0&7&0&0&1&0&0&89&0&3\\\\\n",
    "0&4&0&3&0&4&1&0&87&1\\\\\n",
    "2&1&0&1&1&0&1&4&0&90\\\\\n",
    "\\end{bmatrix}$\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2c09639f1cae464"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Linear classifier for image classification\n",
    "We will use support vector machines to classify the images in the test set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22889364feab4a34"
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 90.80000000000001% \n"
     ]
    }
   ],
   "source": [
    "## load the data\n",
    "train_data = load_images_to_array(train_dir)\n",
    "test_data = load_images_to_array(test_dir)\n",
    "\n",
    "# create the labels\n",
    "train_labels = np.repeat(np.arange(10), 400).reshape(-1, 1)\n",
    "test_labels = np.repeat(np.arange(10), 100).reshape(-1, 1)\n",
    "\n",
    "# hyper parameters\n",
    "c = 0.1\n",
    "iterations = 1000\n",
    "gamma = 0.001\n",
    "\n",
    "# Feature Scaling\n",
    "train_data = cv.normalize(train_data, train_data, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "test_data = cv.normalize(test_data, test_data, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "\n",
    "# reshape the data\n",
    "train_data = train_data.reshape(-1, 400)\n",
    "test_data = test_data.reshape(-1, 400)\n",
    "\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setType(cv.ml.SVM_C_SVC)\n",
    "svm.setC(c)\n",
    "svm.setGamma(gamma)\n",
    "svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, iterations, 1e-6))  # \n",
    "svm.train(train_data, cv.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "# predict the labels\n",
    "result = svm.predict(test_data)[1]\n",
    "\n",
    "# calculate the accuracy\n",
    "matches = np.equal(result, test_labels)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct * (100.0 / result.size)\n",
    "print(f'Accuracy is {accuracy}% ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T19:07:33.923953296Z",
     "start_time": "2023-10-07T19:07:33.319096997Z"
    }
   },
   "id": "a6afb2f665f9f1be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| C     | Gamma | Iterations | Accuracy           |\n",
    "|-------|-------|------------|--------------------|\n",
    "| 0.001 | 0.001 | 1000       | 83.4%              |\n",
    "| 0.001 | 0.001 | 2000       | 83.4%              |\n",
    "| 0.001 | 0.001 | 3000       | 83.4%              |\n",
    "| 0.001 | 0.01  | 1000       | 83.4%              |\n",
    "| 0.001 | 0.01  | 2000       | 83.4%              |\n",
    "| 0.001 | 0.01  | 3000       | 83.4%              |\n",
    "| 0.001 | 0.1   | 1000       | 83.4%              |\n",
    "| 0.001 | 0.1   | 2000       | 83.4%              |\n",
    "| 0.001 | 0.1   | 3000       | 83.4%              |\n",
    "| 0.001 | 1     | 1000       | 83.4%              |\n",
    "| 0.001 | 1     | 2000       | 83.4%              |\n",
    "| 0.001 | 1     | 3000       | 83.4%              |\n",
    "| 0.01  | 0.001 | 1000       | 90.7%              |\n",
    "| 0.01  | 0.001 | 2000       | 90.7%              |\n",
    "| 0.01  | 0.001 | 3000       | 90.7%              |\n",
    "| 0.01  | 0.01  | 1000       | 90.7%              |\n",
    "| 0.01  | 0.01  | 2000       | 90.7%              |\n",
    "| 0.01  | 0.01  | 3000       | 90.7%              |\n",
    "| 0.01  | 0.1   | 1000       | 90.7%              |\n",
    "| 0.01  | 0.1   | 2000       | 90.7%              |\n",
    "| 0.01  | 0.1   | 3000       | 90.7%              |\n",
    "| 0.01  | 1     | 1000       | 90.7%              |\n",
    "| 0.01  | 1     | 2000       | 90.7%              |\n",
    "| 0.01  | 1     | 3000       | 90.7%              |\n",
    "| 0.1   | 0.001 | 1000       | 90.80000000000001% |\n",
    "| 0.1   | 0.001 | 2000       | 90.80000000000001% |\n",
    "| 0.1   | 0.001 | 3000       | 90.80000000000001% |\n",
    "| 0.1   | 0.01  | 1000       | 90.80000000000001% |\n",
    "| 0.1   | 0.01  | 2000       | 90.80000000000001% |\n",
    "| 0.1   | 0.01  | 3000       | 90.80000000000001% |\n",
    "| 0.1   | 0.1   | 1000       | 90.80000000000001% |\n",
    "| 0.1   | 0.1   | 2000       | 90.80000000000001% |\n",
    "| 0.1   | 0.1   | 3000       | 90.80000000000001% |\n",
    "| 0.1   | 1     | 1000       | 90.80000000000001% |\n",
    "| 0.1   | 1     | 2000       | 90.80000000000001% |\n",
    "| 0.1   | 1     | 3000       | 90.80000000000001% |\n",
    "| 1     | 0.001 | 1000       | 90.10000000000001% |\n",
    "| 1     | 0.001 | 2000       | 90.0%              |\n",
    "| 1     | 0.001 | 3000       | 90.10000000000001% |\n",
    "| 1     | 0.01  | 1000       | 90.10000000000001% |\n",
    "| 1     | 0.01  | 2000       | 90.0%              |\n",
    "| 1     | 0.01  | 3000       | 90.10000000000001% |\n",
    "| 1     | 0.1   | 1000       | 90.10000000000001% |\n",
    "| 1     | 0.1   | 2000       | 90.0%              |\n",
    "| 1     | 0.1   | 3000       | 90.10000000000001% |\n",
    "| 1     | 1     | 1000       | 90.10000000000001% |\n",
    "| 1     | 1     | 2000       | 90.0%              |\n",
    "| 1     | 1     | 3000       | 90.10000000000001% |\n",
    "| 10    | 0.001 | 1000       | 89.60000000000001% |\n",
    "| 10    | 0.001 | 2000       | 89.5%              |\n",
    "| 10    | 0.001 | 3000       | 89.30000000000001% |\n",
    "| 10    | 0.01  | 1000       | 89.60000000000001% |\n",
    "| 10    | 0.01  | 2000       | 89.5%              |\n",
    "| 10    | 0.01  | 3000       | 89.30000000000001% |\n",
    "| 10    | 0.1   | 1000       | 89.60000000000001% |\n",
    "| 10    | 0.1   | 2000       | 89.5%              |\n",
    "| 10    | 0.1   | 3000       | 89.30000000000001% |\n",
    "| 10    | 1     | 1000       | 89.60000000000001% |\n",
    "| 10    | 1     | 2000       | 89.5%              |\n",
    "| 10    | 1     | 3000       | 89.30000000000001% |\n",
    "\n",
    "Best accuracy is 90.80000000000001% with parameters {'C': 0.1, 'gamma': 0.001, 'iterations': 1000}\n",
    "The accuracy is lower than the k nearest neighbor method when k = 3 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a68b858ac4b276f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Image classification using a bag of visual words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a132c815de0814a9"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Organize the images into folders based on their category\n",
    "def categorize_images(main_directory, new_directory):\n",
    "    categories = [str(i) for i in range(10)]\n",
    "    for category in categories:\n",
    "        # If the directory already exists, delete it\n",
    "        if os.path.exists(new_directory + '/' + category):\n",
    "            shutil.rmtree(new_directory + '/' + category)\n",
    "        # Create the directory\n",
    "        os.makedirs(new_directory + '/' + category, exist_ok=True)\n",
    "    for filename in os.listdir(main_directory):\n",
    "        if filename.startswith('test_') or filename.startswith('train_'):\n",
    "            category = filename.split('_')[1]\n",
    "            shutil.copy(main_directory + '/' + filename, new_directory + '/' + category + '/' + filename)\n",
    "\n",
    "categorize_images('test', 'bov_test')\n",
    "categorize_images('train', 'bov_train')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T22:29:24.867010460Z",
     "start_time": "2023-10-07T22:29:24.551988143Z"
    }
   },
   "id": "9eadba6e56082869"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.1 load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56584ae59db1d8b6"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# takes all images and convert them to grayscale. \n",
    "# return a dictionary that holds all images category by category. \n",
    "def load_images_from_folder(folder):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        category = []\n",
    "        path = folder + \"/\" + filename\n",
    "        for cat in os.listdir(path):\n",
    "            img = cv.imread(path + \"/\" + cat, 0)\n",
    "            # add noise with high contrast to images\n",
    "            img = ndimage.gaussian_filter(img, sigma=1)\n",
    "            img = cv.normalize(img, None, 0, 255, cv.NORM_MINMAX)\n",
    "            category.append(img)\n",
    "        images[filename] = category\n",
    "    return images\n",
    "\n",
    "\n",
    "images = load_images_from_folder('bov_train')  # take all images category by category \n",
    "test = load_images_from_folder(\"bov_test\")  # take test images \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T22:29:26.216168449Z",
     "start_time": "2023-10-07T22:29:25.767616332Z"
    }
   },
   "id": "468f5451d8819db6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.2 Feature extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "403128e4a71d8f78"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creates descriptors using sift \n",
    "def sift_features(images_bov, features=200):\n",
    "    sift = cv.SIFT_create(nfeatures=features, contrastThreshold=0.001, edgeThreshold=55)\n",
    "    descriptor_list_sift = []\n",
    "    sift_vectors = {}\n",
    "\n",
    "    for key, value in images_bov.items():\n",
    "        features = []\n",
    "        for img_sift in value:\n",
    "            kp, des = sift.detectAndCompute(img_sift, None)\n",
    "            #if des is not None:\n",
    "            descriptor_list_sift.extend(des)\n",
    "            features.append(des)\n",
    "                \n",
    "        sift_vectors[key] = features\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    descriptor_list_sift = scaler.fit_transform(np.array(descriptor_list_sift))\n",
    "\n",
    "    return descriptor_list_sift, sift_vectors\n",
    "\n",
    "sifts = sift_features(images)\n",
    "descriptor_list = sifts[0]\n",
    "all_bovw_feature = sifts[1]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "descriptor_list = scaler.fit_transform(np.array(descriptor_list))\n",
    "\n",
    "test_bovw_feature = sift_features(test)[1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T22:29:28.540298124Z",
     "start_time": "2023-10-07T22:29:26.351526570Z"
    }
   },
   "id": "987eaf1b64a6c592"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "# A k-means clustering algorithm who takes 2 parameter which is number \n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    return visual_words\n",
    "\n",
    "\n",
    "# Takes the central points which is visual words    \n",
    "visual_words = kmeans(150, descriptor_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T22:30:02.208663536Z",
     "start_time": "2023-10-07T22:29:28.539994446Z"
    }
   },
   "id": "8bf1110aaf2467d5"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def find_index(image, center):\n",
    "    count = 0\n",
    "    ind = 0\n",
    "    for i in range(len(center)):\n",
    "        if (i == 0):\n",
    "            count = distance.euclidean(image, center[i])\n",
    "            #count = L1_dist(image, center[i])\n",
    "        else:\n",
    "            dist = distance.euclidean(image, center[i])\n",
    "            #dist = L1_dist(image, center[i])\n",
    "            if (dist < count):\n",
    "                ind = i\n",
    "                count = dist\n",
    "    return ind\n",
    "\n",
    "\n",
    "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
    "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key, value in all_bovw.items():\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            if img is not None:\n",
    "                for each_feature in img:\n",
    "                    ind = find_index(each_feature, centers)\n",
    "                    histogram[ind] += 1\n",
    "                # Normalize the histogram\n",
    "                histogram /= np.sum(histogram)\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "\n",
    "\n",
    "# Creates histograms for train data    \n",
    "bovw_train = image_class(all_bovw_feature, visual_words)\n",
    "# Creates histograms for test data\n",
    "bovw_test = image_class(test_bovw_feature, visual_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T22:30:26.085187222Z",
     "start_time": "2023-10-07T22:30:02.230351660Z"
    }
   },
   "id": "9a8d2da121a59222"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# 1-NN algorithm. We use this for predict the class of test images.\n",
    "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
    "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
    "def L1_dist(vec1, vec2):\n",
    "    return np.linalg.norm(np.subtract(np.array(vec1), np.array(vec2)))    \n",
    "def knn(images, tests):\n",
    "    num_test = 0\n",
    "    correct_predict = 0\n",
    "    class_based = {}\n",
    "\n",
    "    for test_key, test_val in tests.items():\n",
    "        class_based[test_key] = [0, 0]  # [correct, all]\n",
    "        for tst in test_val:\n",
    "            predict_start = 0\n",
    "            #print(test_key)\n",
    "            minimum = 0\n",
    "            key = \"a\"  #predicted\n",
    "            for train_key, train_val in images.items():\n",
    "                for train in train_val:\n",
    "                    if (predict_start == 0):\n",
    "                        minimum = distance.euclidean(tst, train)\n",
    "                        #minimum = L1_dist(tst,train)\n",
    "                        key = train_key\n",
    "                        predict_start += 1\n",
    "                    else:\n",
    "                        dist = distance.euclidean(tst, train)\n",
    "                        #dist = L1_dist(tst,train)\n",
    "                        if (dist < minimum):\n",
    "                            minimum = dist\n",
    "                            key = train_key\n",
    "\n",
    "            if (test_key == key):\n",
    "                correct_predict += 1\n",
    "                class_based[test_key][0] += 1\n",
    "            num_test += 1\n",
    "            class_based[test_key][1] += 1\n",
    "            #print(minimum)\n",
    "    return [num_test, correct_predict, class_based]\n",
    "\n",
    "\n",
    "# Call the knn function    \n",
    "results_bowl = knn(bovw_train, bovw_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T22:30:42.816689395Z",
     "start_time": "2023-10-07T22:30:26.128869266Z"
    }
   },
   "id": "e15acfab7e41c2e9"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: %74.7\n",
      "\n",
      "Class based accuracies: \n",
      "\n",
      "0 : %98.0\n",
      "1 : %96.0\n",
      "2 : %62.0\n",
      "3 : %74.0\n",
      "4 : %77.0\n",
      "5 : %55.00000000000001\n",
      "6 : %68.0\n",
      "7 : %85.0\n",
      "8 : %69.0\n",
      "9 : %63.0\n"
     ]
    }
   ],
   "source": [
    " #Calculates the average accuracy and class based accuracies.  \n",
    "def accuracy(results):\n",
    "    avg_accuracy = (results[1] / results[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
    "    print(\"\\nClass based accuracies: \\n\")\n",
    "    for key, value in results[2].items():\n",
    "        acc = (value[0] / value[1]) * 100\n",
    "        print(key + \" : %\" + str(acc))\n",
    "\n",
    "\n",
    "# sort the dictionary by key\n",
    "results_bowl[2] = dict(sorted(results_bowl[2].items()))\n",
    "# Calculates the accuracies and write the results to the console.       \n",
    "accuracy(results_bowl) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T22:30:42.859058056Z",
     "start_time": "2023-10-07T22:30:42.858709791Z"
    }
   },
   "id": "8a87cb045373ac34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "48017245321ca0dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
